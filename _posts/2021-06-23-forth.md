---
title: "[Elementary Sampling] Estimation of a population mean"
tags:
  #- Blog
  #- MathJax
  #- Jekyll
  #- LaTeX
use_math: true
---

**Elementary Sampling 4.3 정리 및 실험**
================
Daniel Lee
2021-06-23

-   [1 **Estimation of a population
    mean**](#estimation-of-a-population-mean)
    -   [1.1 **기초통계량**](#기초통계량)
    -   [1.2 **목표**](#목표)
        -   [1.2.1 **문제점**](#문제점)
    -   [1.3 **모분산의 비편향 추정량**](#모분산의-비편향-추정량)
    -   [1.4 **95% 신뢰구간**](#95-신뢰구간)
    -   [1.5 **Finite Population
        Correction**](#finite-population-correction)
        -   [1.5.1 FPC](#fpc)
        -   [1.5.2 복원 추출에서의 분산과
            추정](#복원-추출에서의-분산과-추정)
-   [2 **Estimation of a population
    total**](#estimation-of-a-population-total)
    -   [2.1 **목표**](#목표-1)
    -   [2.2 **추정**](#추정)
-   [3 **함수로 실험해보자**](#함수로-실험해보자)
    -   [3.1 **실험목표**](#실험목표)
    -   [3.2 **실험용 함수 만들기**](#실험용-함수-만들기)
    -   [3.3 **실험**](#실험)
        -   [3.3.1 **라이브러리**](#라이브러리)
        -   [3.3.2 **실험**](#실험-1)
        -   [3.3.3 **그래프**](#그래프)
    -   [3.4 **실험결과 요약**](#실험결과-요약)

# 1 **Estimation of a population mean**

-   **주어진 값**

모집단으로부터 단순확률로 비복원 추출한 n개의 표본이다.

*y*<sub>1</sub>, ⋯, *y*<sub>*n*</sub>

``` r
N <- 484

y <- c(33.50, 32.00, 52.00,
       43.00, 40.00, 41.00,
       45.00, 42.50, 39.00)

n <- length(y)

cat('N, n = ', N, n, '\n',
    'y  = ', y)
```

    ## N, n =  484 9 
    ##  y  =  33.5 32 52 43 40 41 45 42.5 39

## 1.1 **기초통계량**

표본평균과 표본분산을 구해보자.

*ȳ* = ∑*y*<sub>*i*</sub>/*n*

$$s^2=\\frac{1}{n-1}\\sum (y\_i-\\bar{y})^2$$

``` r
y_bar <- sum(y/n) # mean(y)
s_sq <- 1/(n-1) * sum((y-y_bar)^2) # sd(y)^2

cat('y_bar = ', y_bar, '\n',
    's_sq  = ', s_sq)
```

    ## y_bar =  40.88889 
    ##  s_sq  =  35.67361

*ȳ*와 *s*<sup>2</sup>은 표본평균과 표본분산이고 궁금한 것은 모집단의
생김새이다. 즉, 우리는 *μ*와 *σ*<sup>2</sup>을 알고싶다.

## 1.2 **목표**

*E*(*ȳ*) = *μ* → (*μ* = ?)

$$V(\\bar{y})=\\frac{\\sigma^2}{n}\\frac{N-n}{N-1} \\rightarrow (\\sigma^2 = ?)$$

``` r
# eval=FALSE

mu <- mean( y_bar ) # y추출 실험을 여러번 해서 y_bar가 여러개여야 구할 수 있다
V_y_bar <- sigma^2/n * (N-n)/(N-1) # s^2이 여러개여야 구할 수 있다
```

*μ*, *σ*<sup>2</sup>를 직접적으로 알 수는 없지만 비편향 추정량을 통해
추정해볼 수는 있다.

### 1.2.1 **문제점**

> -   우선 *μ*는 *E*(*ȳ*)로 추정할 수 있지만 둘은 완전히 같을 수는
>     없다.  
> -   따라서 우리는 모평균과 표본평균의 차이에 대한 기준으로써 *ȳ*의
>     분산 즉, *V*(*ȳ*)를 알아야 한다..  
> -   하지만 *σ*<sup>2</sup>을 알 수가 없으므로 이를 해결할 방법을
>     찾아야 한다.

## 1.3 **모분산의 비편향 추정량**

*σ*<sup>2</sup>을 비편향 추정량으로 대치하면 아래와 같다.(단, 이는
유한모집단 비복원 추출에 해당함)

$E(s^2) = \\frac{N}{N-1}\\sigma^2 \\Rightarrow E(\\frac{N-1}{N}s^2)=\\sigma^2$

$V(\\bar{y})=E(\\frac{N-1}{N}s^2)\\frac{1}{n}\\frac{N-n}{N-1}=E(\\frac{s^2}{n}\\frac{N-n}{N})$

$\\therefore\\hat{V}(\\bar{y})=\\frac{s^2}{n}\\frac{N-n}{N} : unbiased est.of. V(\\bar{y})$

``` r
V_hat_y_bar <- s_sq/n * (N-n)/N

cat('V_hat_y_bar = ', V_hat_y_bar)
```

    ## V_hat_y_bar =  3.890029

## 1.4 **95% 신뢰구간**

> 고등학교에서 배운 95% 신뢰구간의 z-score는 1.96으로 알고있지만 2를
> 사용한다.

두가지 이유가 있는데 첫째로는 1.96보다 2의 범위가 더 넓으므로 분산을
과대추정을 하는 셈이어서 추정을 보수적으로 할 수 있다는 점(즉, 분산의
과소추정은 문제가 될지 몰라도 **과대추정은 문제가 되지 않음**을 의미),
두번째로는 뒤에서 2라는 숫자 자체의 계산의 편리함 덕에 자주 사용한다.
뒤에서 배울 Selecting of Sample Size에서 1.96이나 2나 별반 차이가 없으나
2가 **계산하기 편하다**는 것을 알 수 있다.

$$95\\%\\ CI :\\ \\bar{y}\\ \\pm\\ 2\\sqrt{\\hat{V}(\\bar{y})}$$

``` r
B <- 2*sqrt(V_hat_y_bar)

cat('B  = ', B, '\n',
    '95% CI : ', y_bar - B, y_bar + B)
```

    ## B  =  3.944631 
    ##  95% CI :  36.94426 44.83352

## 1.5 **Finite Population Correction**

### 1.5.1 FPC

-   유한모집단 수정계수 $\\frac{N-n}{N-1}$을 FPC라고 부른다. *V*(*ȳ*)의
    공식에 붙어있는 것을 볼 수 있다. 이는 모집단이 **유한모집단** 일때,
    추출 방법이 **비복원 추출**일 때 분산의 공식에 곱해진다.

-   일반적으로
    $n\\leq \\frac{N}{20} \\Leftrightarrow \\frac{N-n}{N-1} \\geq 0.95$
    이면 FPC를 생락할 수 있다.

-   N이 알려지지 않았을 때에도 N을 n에 비해 아주 큰 값으로 가정하여
    FPC를 무시할 수 있다.

### 1.5.2 복원 추출에서의 분산과 추정

각 표본이 서로 독립일 때 *ȳ*의 분산은 *E*((*ȳ* − *μ*)<sup>2</sup>)
이므로

$$E((\\bar{y} - \\mu)^2) = E(\\ (\\sum\_{i=1} ^ {n} \\frac{y\_i}{n}  - \\mu)^2)$$

$$=E(\\ (\\sum\_{i=1} ^ {n} \\frac{y\_i - \\mu}{n})^2) =  \\frac{E(\\ (\\ \\sum\_{i=1} ^ {n} (y\_i - \\mu)\\ )^2)}{n^2}$$
한편,

$$E(\\ (\\ \\sum\_{i=1} ^ {n} (y\_i - \\mu)\\ )^2) = E(\\ \\sum\_{i=1} ^ {n} (y\_i-\\mu)^2) - \\sum\_{i\\neq j}Cov(y\_i, \\ y\_j )\\ 이고$$

*y*<sub>*i*</sub>는 서로 독립인 표본이므로

$$E((\\bar{y} - \\mu)^2) = \\frac{E(\\ \\sum\_{i=1} ^ {n} (y\_i-\\mu)^2)}{n^2} = \\frac{n\\sigma^2}{n^2} = \\frac{\\sigma^2}n$$

$$\\therefore V(\\bar{y}) = \\frac{\\sigma^2}n$$

-   무한모집단 또는 복원추출시
    *E*(*s*<sup>2</sup>) = *σ*<sup>2</sup>임과
    $\\hat{V}(\\bar{y}) = \\frac{s^2}n$에 대한 증명은 생략

# 2 **Estimation of a population total**

-   **알고있는 것**

``` r
cat('N, n = ', N, n, '\n',
    'y_bar  = ', y_bar, '\n',
    'V_hat_y_bar = ', V_hat_y_bar, '\n',
    'Bound of error = ', B)
```

    ## N, n =  484 9 
    ##  y_bar  =  40.88889 
    ##  V_hat_y_bar =  3.890029 
    ##  Bound of error =  3.944631

## 2.1 **목표**

구하려는 값은 population total 즉, 모집단 값의 총합이다. 만약 모평균을
우리가 알고있다면 **모집단의 총합은 모평균에 모집단의 수 만큼을 곱**한
것으로 구할 수 있을 것이다.

## 2.2 **추정**

우리는 직관적으로 **평균의 추정량에 모집단의 수 만큼을 곱**하면 총합의
추정량이 될 것 같다고 생각할 수 있다. 그러므로 우리는 모집단 총합의
추정량 *τ̂*을 아래와 같이 추정할 수 있다.

*τ̂* = *N**μ̂* = *N**ȳ*

우리가 구한 것은 추정량이므로 산포도인 분산이 필요하다. 하지만 아래에서
알 수 있듯이 분산 또한 추정량을 알 수밖에 없다.(표본평균도 분산을 몰라서
분산의 추정량을 구했던 것을 기억하자)

*V*(*τ̂*) = *V*(*N**ȳ*) = *N*<sup>2</sup>*V*(*ȳ*)

따라서 **총합 추정량의 분산의 추정량**은 아래와 같다.

*V̂*(*τ̂*) = *N*<sup>2</sup>*V̂*(*ȳ*)

직접 계산해보면 아래와 같다.

``` r
tau_hat <- N*y_bar
V_hat_tau_hat <- N^2*V_hat_y_bar
B_tau <- 2*sqrt(V_hat_tau_hat)

cat('tau_hat = ', tau_hat, '\n',
    'V_hat_tau_hat  = ', V_hat_tau_hat, '\n',
    'Bound of error = ', B_tau, '\n',
    '95% CI : ', tau_hat - B_tau, tau_hat + B_tau)
```

    ## tau_hat =  19790.22 
    ##  V_hat_tau_hat  =  911262.6 
    ##  Bound of error =  1909.201 
    ##  95% CI :  17881.02 21699.42

# 3 **함수로 실험해보자**

## 3.1 **실험목표**

실험의 목적은 모집단의 평균과 총합으로부터 표본의 평균이 얼마나 떨어져
있는지, 분산의 추정량의 분포는 어떠한지, 둘 사이의 상관관계가 있는지
시각화 하여 알아보는 실험이다.

## 3.2 **실험용 함수 만들기**

우선, 위에서 구하는 과정들을 토대로 평균과 총합을 추정하는 간단한 함수를
만들어보자.

인풋 : 자료값 y, 모집단 수 N 가 주어진다.(표본 수는 자료값 y에서 알 수
있다.)

아웃풋 : 평균의 추정값, 총합의 추정값, 분산의 추정값등의 서머리

``` r
est_summary <- function(y, N){

  n <- length(y)
  y_bar <- mean(y)
  s_sq <- sd(y)^2
  
  V_hat_y_bar <- s_sq/n * (N-n)/N
  B <- 2*sqrt(V_hat_y_bar)

  cat('N, n = ', N, n, '\n',
    'y_bar  = ', y_bar, '\n',
    'V_hat_y_bar = ', V_hat_y_bar, '\n',
    'Bound of error = ', B, '\n',
    '95% CI : ', y_bar - B, y_bar + B)
}

est_summary(y, N)
```

    ## N, n =  484 9 
    ##  y_bar  =  40.88889 
    ##  V_hat_y_bar =  3.890029 
    ##  Bound of error =  3.944631 
    ##  95% CI :  36.94426 44.83352

이렇게 하면 편하겠지만.. 랜덤 자료로 실험하기엔 좋지 않다. 실행환경을
캡쳐하는 쪽으로 접근해보자.

``` r
make_est <- function(y, N, ...){

  n <- length(y)
  y_bar <- mean(y)
  V <- sd(y)^2/n * (N-n)/N

  environment() # 실행환경 자체를 반환한다.
}

mu_estimation <- make_est(y, N)
mu_estimation
```

    ## <environment: 0x0000000016b68600>

``` r
c(mu_estimation$y_bar, mu_estimation$V)
```

    ## [1] 40.888889  3.890029

이제 실험을 위한 함수 셋팅은 끝났다. 우선 모평균에 대해 실험을
진행해보자.

## 3.3 **실험**

### 3.3.1 **라이브러리**

``` r
library(ggplot2) # 그래프 그리기용 함수
```

### 3.3.2 **실험**

``` r
N <- 2000
mean <- 100
standard_deviation <- 10

set.seed(1004) # 아무 숫자나 상관 없지만 같은 실험 결과를 원하면 같은 숫자를 쓴다.
population <- rnorm(N, mean, standard_deviation)


y_list <- lapply(1:100, function(i) sample(population, 100, replace = FALSE))

mu_estims <- lapply(y_list, function(y) make_est(y, N))

mu_hats <- vapply(mu_estims, function(e) e$y_bar, numeric(1))
mu_V_hats <- vapply(mu_estims, function(e) e$V, numeric(1))

head(mu_hats)
```

    ## [1]  98.66712  99.92627 100.09452  98.63943  97.99991  98.70797

모평균을 100으로 설정해 놓았고 표본 평균들이 거기에 근접하게 나오는
것으로 보인다.

``` r
head(mu_V_hats)
```

    ## [1] 1.0825023 1.2457091 1.1046397 0.9683728 0.9495014 0.7868425

모표준편차를 10으로 즉, 모분산을 100으로 설정해놓았다. 표본의 수가
100개이므로 얼추 100으로 나눈 값인 1정도가 나온다고 보면 되겠다.

(1.2)의 공식으로 구한 표본평균의 모분산 값은 아래와 같다.

``` r
( True_V <- standard_deviation^2/100 * (N-100)/(N-1) )
```

    ## [1] 0.9504752

### 3.3.3 **그래프**

이제 그래프로 살펴보자.

``` r
hist(mu_hats, main="Hitogram of mu_hats", col='gray')
```

<img src="4장_files/figure-gfm/unnamed-chunk-14-1.png" style="display: block; margin: auto;" />

*μ̂*들의 그래프는 만족스러운 정규분포를 띄고있다. 원래도 정규성이 보장된
추정량인데다 30개 이상의 표본으로 CLT조건을 만족하여서 정규분포와 유사한
그래프를 그린다.

``` r
hist(mu_V_hats, main="Hitogram of mu_V_hats", col='grey')
```

<img src="4장_files/figure-gfm/unnamed-chunk-15-1.png" style="display: block; margin: auto;" />

*V̂*(*μ̂*)들의 그래프 또한 정규분포에 가까운 모습인데, 표본 수가 적은
상황이라면 제곱합의 분포이므로 직관적으로 카이제곱분포(또는 감마분포)가
들어갈 것만 같다.(표본 수를 작게 줄여보면 직관과 맞는 그래프가 나온다.)
하지만 여기서는 표본 수가 CLT조건을 충분하게 만족할 만큼 크기 때문에
정규성을 띠는 것으로 보인다.

``` r
plot(mu_hats, mu_V_hats)
abline(h=True_V, v=100, col='lightgray', lty=2, lwd=1)
```

<img src="4장_files/figure-gfm/unnamed-chunk-16-1.png" style="display: block; margin: auto;" />

*μ̂*과 *V̂*(*μ̂*)의 산점도이다. 위에서 보았듯이 각각은 정규성을 어느정도
띠고 평균 근처에 몰려있는 것을 볼 수 있었다. 하지만 이 그래프에서는
추정에서 두 값 모두 참값에 가까운 점은 그다지 많다고 말할 수 없어보인다.
**오히려 크게 벗어나지 않는 범위 내에서 골고루 퍼져있는 모습**이다.

공식과 수학적인 측면에서 보았을때엔 서로 완전한 독립은 아니지만, 평균을
정확히 추정했다고 해서 분산도 정확하게 추정한다던지 분산이 정확하게
추정되었다 해서 평균도 정확히 추정 되었을 것이라는 주장은 할 수 없는
것으로 보인다.

## 3.4 **실험결과 요약**

-   *μ̂*과 *V̂*(*μ̂*)은 표본 수가 큰 이유에서 인지 모두 정규성을
    보였다.(표본 수를 줄이면 *V̂*(*μ̂*)은 카이제곱 분포를 따르는 것으로
    보였다.)

-   *μ̂*과 *V̂*(*μ̂*)이 모두 정규성을 가졌지만 **한 쪽의 정확한 추정이 다른
    한쪽의 추정의 정확도를 보장하진 못하였다.** 오히려 관계가 없이
    참값의 점으로부터 일정한 범위 내에서 골고루 분포했다.

**Elementary Sampling 4.3 정리**
================
Daniel Lee
2021-06-22

-   [1 **Estimation of a population
    mean**](#estimation-of-a-population-mean)
    -   [1.1 **기초통계량**](#기초통계량)
    -   [1.2 **목표**](#목표)
        -   [1.2.1 **문제점**](#문제점)
    -   [1.3 **모분산의 비편향 추정량**](#모분산의-비편향-추정량)
    -   [1.4 **95% 신뢰구간**](#95-신뢰구간)
    -   [1.5 **Finite Population
        Correction**](#finite-population-correction)
        -   [1.5.1 FPC](#fpc)
        -   [1.5.2 복원 추출에서의 분산과
            추정](#복원-추출에서의-분산과-추정)

# 1 **Estimation of a population mean**

**주어진 값**

-   모집단으로부터 단순확률로 비복원 추출한 n개의 표본이다.

*y*<sub>1</sub>, ⋯, *y*<sub>*n*</sub>

``` r
N <- 484

y <- c(33.50, 32.00, 52.00,
       43.00, 40.00, 41.00,
       45.00, 42.50, 39.00)

n <- length(y)

cat('N, n = ', N, n, '\n',
    'y  = ', y)
```

    ## N, n =  484 9 
    ##  y  =  33.5 32 52 43 40 41 45 42.5 39

## 1.1 **기초통계량**

*ȳ* = ∑*y*<sub>*i*</sub>/*n*

$s^2=\\frac{1}{n-1}\\sum (y\_i-\\bar{y})^2$

``` r
y_bar <- sum(y/n)
s_sq <- 1/(n-1) * sum((y-y_bar)^2)

cat('y_bar = ', y_bar, '\n',
    's_sq  = ', s_sq)
```

    ## y_bar =  40.88889 
    ##  s_sq  =  35.67361

위에서 구한 *ȳ*와 *s*<sup>2</sup>은 표본평균과 표본분산이고 궁금한 것은
모집단의 생김새이다. 즉, 우리는 *μ*와 *σ*<sup>2</sup>을 알고싶다.

## 1.2 **목표**

*E*(*ȳ*) = *μ* → (*μ* = ?)

$V(\\bar{y})=\\frac{\\sigma^2}{n}\\frac{N-n}{N-1} \\rightarrow (\\sigma^2 = ?)$

``` r
# eval=FALSE

mu <- mean( y_bar ) # y추출 실험을 여러번 해서 y_bar가 여러개여야 구할 수 있다
V_y_bar <- sigma^2/n * (N-n)/(N-1) # s^2이 여러개여야 구할 수 있다
```

*μ*, *σ*<sup>2</sup>를 직접적으로 알 수는 없지만 비편향 추정량을 통해
추정해볼 수는 있다.

### 1.2.1 **문제점**

> -   우선 *μ*는 *E*(*ȳ*)로 추정할 수 있지만 둘은 완전히 같을 수는
>     없다.  
> -   따라서 우리는 모평균과 표본평균의 차이에 대한 기준으로써 *ȳ*의
>     분산 즉, *V*(*ȳ*)를 알아야 한다..  
> -   하지만 *σ*<sup>2</sup>을 알 수가 없으므로 이를 해결할 방법을
>     찾아야 한다.

## 1.3 **모분산의 비편향 추정량**

*σ*<sup>2</sup>을 비편향 추정량으로 대치하면 아래와 같다.(단, 이는
유한모집단 비복원 추출에 해당함)

$E(s^2) = \\frac{N}{N-1}\\sigma^2 \\Rightarrow E(\\frac{N-1}{N}s^2)=\\sigma^2$

$ V({y})=E(s^2)=E()$

$\\therefore\\hat{V}(\\bar{y})=\\frac{s^2}{n}\\frac{N-n}{N} : unbiased est.of. V(\\bar{y})$

``` r
V_hat_y_bar <- s_sq/n * (N-n)/N

cat('V_hat_y_bar = ', V_hat_y_bar)
```

    ## V_hat_y_bar =  3.890029

## 1.4 **95% 신뢰구간**

고등학교에서 배운 95% 신뢰구간의 z-score는 1.96으로 알고있지만 2를
사용한다.

두가지 이유가 있는데 첫째로는 1.96보다 2의 범위가 더 넓으므로 분산을
과대추정을 하는 셈이어서 추정을 보수적으로 할 수 있다는 점(즉, 분산의
과소추정은 문제가 될지 몰라도 **과대추정은 문제가 되지 않음**을 의미),
두번째로는 뒤에서 2라는 숫자 자체의 계산의 편리함 덕에 자주 사용한다.
뒤에서 배울 Selecting of Sample Size에서 1.96이나 2나 별반 차이가 없으나
2가 **계산하기 편하다**는 것을 알 수 있다.

$95\\%\\ CI :\\ \\bar{y}\\ \\pm\\ 2\\sqrt{\\hat{V}(\\bar{y})}$

``` r
V_hat_y_bar <- s_sq/n * (N-n)/N
B <- 2*sqrt(V_hat_y_bar)

cat('B  = ', B, '\n',
    '95% CI : ', y_bar - B, y_bar + B)
```

    ## B  =  3.944631 
    ##  95% CI :  36.94426 44.83352

## 1.5 **Finite Population Correction**

### 1.5.1 FPC

-   유한모집단 수정계수 $\\frac{N-n}{N-1}$을 FPC라고 부른다. *V*(*ȳ*)의
    공식에 붙어있는 것을 볼 수 있다. 이는 모집단이 **유한모집단** 일때,
    추출 방법이 **비복원 추출**일 때 분산의 공식에 곱해진다.

-   일반적으로
    $n\\leq \\frac{N}{20} \\Leftrightarrow \\frac{N-n}{N-1} \\geq 0.95$
    이면 FPC를 생락할 수 있다.

-   N이 알려지지 않았을 때에도 N을 n에 비해 아주 큰 값으로 가정하여
    FPC를 무시할 수 있다.

### 1.5.2 복원 추출에서의 분산과 추정

각 표본이 서로 독립일 때 *ȳ*의 분산은 *E*((*ȳ* − *μ*)<sup>2</sup>)
이므로

$E((\\bar{y} - \\mu)^2) = E(\\ (\\sum\_{i=1} ^ {n} \\frac{y\_i}{n} - \\mu)^2) = E(\\ (\\sum\_{i=1} ^ {n} \\frac{y\_i - \\mu}{n})^2) = \\frac{E(\\ \\{\\sum\_{i=1} ^ {n} (y\_i - \\mu)\\}^2)}{n^2}$

$E(\\ \\{\\sum\_{i=1} ^ {n} (y\_i - \\mu)\\}^2) = E(\\ \\sum\_{i=1} ^ {n} (y\_i-\\mu)^2 - \\sum \\sum\_{i \\neq j} (y\_i-\\mu)(y\_j-\\mu)\\ )$

*y*<sub>*i*</sub>는 서로 독립인 표본이므로

$ E(({y} - )^2) = = = n$

$$\\therefore V(\\bar{y}) = \\frac{\\sigma^2}n$$
\* 무한모집단 또는 복원추출시 *E*(*s*<sup>2</sup>) = *σ*<sup>2</sup>임과
$\\hat{V}(\\bar{y}) = \\frac{s^2}n$에 대한 증명은 생략
